{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# records in train: 4040\n",
      "# records in test: 1631\n",
      "4040\n",
      "994\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "orig_train = json.loads(open(\"train.json\").read())\n",
    "orig_test = json.loads(open(\"test.json\").read())\n",
    "\n",
    "print \"# records in train:\",len(orig_train)\n",
    "print \"# records in test:\",len(orig_test)\n",
    "\n",
    "orig_train_text = []\n",
    "orig_train_labels = []\n",
    "kaggle_test_text = []\n",
    "kaggle_test_id = []\n",
    "#TODO: create more features arrays here\n",
    "\n",
    "for record in orig_train:\n",
    "    orig_train_text.append(record['request_text'])\n",
    "    if record['requester_received_pizza']:\n",
    "        orig_train_labels.append(1)\n",
    "    else:\n",
    "        orig_train_labels.append(0)\n",
    "\n",
    "print len(orig_train_labels)\n",
    "print sum(orig_train_labels)\n",
    "print orig_train_labels[:50]\n",
    "\n",
    "for record in orig_test:\n",
    "    kaggle_test_text.append(record['request_text_edit_aware'])\n",
    "    kaggle_test_id.append(record['request_id'])\n",
    "    #TODO: build more features arrays here\n",
    "\n",
    "#pprint(test[1])\n",
    "#print orig_train_labels[:10]\n",
    "#print orig_train_text[0]\n",
    "#print kaggle_test_text[1]\n",
    "\n",
    "# Break data up into training and testing data\n",
    "train_text = orig_train_text[:3500]\n",
    "train_labels = orig_train_labels[:3500]\n",
    "\n",
    "dev_text = orig_train_text[3501:]\n",
    "dev_labels = orig_train_labels[3501:]\n",
    "\n",
    "\n",
    "def write_solution_to_file(prediction, filename):\n",
    "    if len(prediction) == len(kaggle_test_id):\n",
    "        print \"Writing to file\", filename\n",
    "        outfile = open(filename,'w')\n",
    "        outfile.write(\"request_id,requester_received_pizza\\n\")\n",
    "        for i in range(0,len(prediction)):\n",
    "            outfile.write(kaggle_test_id[i]+','+str(prediction[i])+'\\n')\n",
    "        return 1\n",
    "    else:\n",
    "        print \"Prediction dimension mismatch\"\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNB f1 score:  0.286995515695\n",
      "MNB best params: {'alpha': 1e-05}\n",
      "Writing to file test-submission.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn import metrics\n",
    "\n",
    "cv_train = CountVectorizer()\n",
    "dtm_train = cv_train.fit_transform(train_text)\n",
    "cv_dev = CountVectorizer(vocabulary=cv_train.get_feature_names())\n",
    "dtm_dev = cv_dev.fit_transform(dev_text)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb_parameters = {'alpha':[.1,.001,.0001,.00001]}\n",
    "mnbgs = GridSearchCV(mnb, mnb_parameters)\n",
    "mnbgs.fit(dtm_train, train_labels)\n",
    "mnb_pred = mnbgs.predict(dtm_dev)\n",
    "best_params = mnbgs.best_params_\n",
    "\n",
    "print \"\\nMNB f1 score: \", metrics.f1_score(dev_labels, mnb_pred, average='binary')\n",
    "print \"MNB best params:\", best_params\n",
    "\n",
    "# Now that we have scanned some parameters, we can proceed with the best one but train with all data\n",
    "cv_all = CountVectorizer()\n",
    "dtm_all = cv_all.fit_transform(orig_train_text)\n",
    "cv_kaggle = CountVectorizer(vocabulary=cv_all.get_feature_names())\n",
    "dtm_kaggle = cv_kaggle.fit_transform(kaggle_test_text)\n",
    "\n",
    "mnb_kaggle = MultinomialNB(alpha=best_params['alpha'])\n",
    "mnb_kaggle.fit(dtm_all, orig_train_labels)\n",
    "mnb_pred = mnb_kaggle.predict(dtm_kaggle)\n",
    "\n",
    "write_solution_to_file(mnb_pred, \"test-submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
