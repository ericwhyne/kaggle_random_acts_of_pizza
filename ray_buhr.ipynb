{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##W207 Final Project - Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Acts of Pizza\n",
    "\n",
    "This dataset includes 5671 requests collected from the Reddit community Random Acts of Pizza between December 8, 2010 and September 29, 2013 (retrieved on September 30, 2013). All requests ask for the same thing: a free pizza. The outcome of each request -- whether its author received a pizza or not -- is known. Meta-data includes information such as: time of the request, activity of the requester, community-age of the requester, etc.\n",
    "\n",
    "Each JSON entry corresponds to one request (the first and only request by the requester on Random Acts of Pizza). We have removed fields from the test set which would not be available at the time of posting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data fields**\n",
    "\n",
    "\"giver_username_if_known\": Reddit username of giver if known, i.e. the person satisfying the request (\"N/A\" otherwise).\n",
    "\n",
    "\"number_of_downvotes_of_request_at_retrieval\": Number of downvotes at the time the request was collected.\n",
    "\n",
    "\"number_of_upvotes_of_request_at_retrieval\": Number of upvotes at the time the request was collected.\n",
    "\n",
    "\"post_was_edited\": Boolean indicating whether this post was edited (from Reddit).\n",
    "\n",
    "\"request_id\": Identifier of the post on Reddit, e.g. \"t3_w5491\".\n",
    "\n",
    "\"request_number_of_comments_at_retrieval\": Number of comments for the request at time of retrieval.\n",
    "\n",
    "\"request_text\": Full text of the request.\n",
    "\n",
    "\"request_text_edit_aware\": Edit aware version of \"request_text\". We use a set of rules to strip edited comments indicating the success of the request such as \"EDIT: Thanks /u/foo, the pizza was delicous\".\n",
    "\n",
    "\"request_title\": Title of the request.\n",
    "\n",
    "\"requester_account_age_in_days_at_request\": Account age of requester in days at time of request.\n",
    "\n",
    "\"requester_account_age_in_days_at_retrieval\": Account age of requester in days at time of retrieval.\n",
    "\n",
    "\"requester_days_since_first_post_on_raop_at_request\": Number of days between requesters first post on RAOP and this request (zero if requester has never posted before on RAOP).\n",
    "\n",
    "\"requester_days_since_first_post_on_raop_at_retrieval\": Number of days between requesters first post on RAOP and time of retrieval.\n",
    "\n",
    "\"requester_number_of_comments_at_request\": Total number of comments on Reddit by requester at time of request.\n",
    "\n",
    "\"requester_number_of_comments_at_retrieval\": Total number of comments on Reddit by requester at time of retrieval.\n",
    "\n",
    "\"requester_number_of_comments_in_raop_at_request\": Total number of comments in RAOP by requester at time of request.\n",
    "\n",
    "\"requester_number_of_comments_in_raop_at_retrieval\": Total number of comments in RAOP by requester at time of retrieval.\n",
    "\n",
    "\"requester_number_of_posts_at_request\": Total number of posts on Reddit by requester at time of request.\n",
    "\n",
    "\"requester_number_of_posts_at_retrieval\": Total number of posts on Reddit by requester at time of retrieval.\n",
    "\n",
    "\"requester_number_of_posts_on_raop_at_request\": Total number of posts in RAOP by requester at time of request.\n",
    "\n",
    "\"requester_number_of_posts_on_raop_at_retrieval\": Total number of posts in RAOP by requester at time of retrieval.\n",
    "\n",
    "\"requester_number_of_subreddits_at_request\": The number of subreddits in which the author had already posted in at the time of request.\n",
    "\n",
    "\"requester_received_pizza\": Boolean indicating the success of the request, i.e., whether the requester received pizza.\n",
    "\n",
    "\"requester_subreddits_at_request\": The list of subreddits in which the author had already posted in at the time of request.\n",
    "\n",
    "\"requester_upvotes_minus_downvotes_at_request\": Difference of total upvotes and total downvotes of requester at time of request.\n",
    "\n",
    "\"requester_upvotes_minus_downvotes_at_retrieval\": Difference of total upvotes and total downvotes of requester at time of retrieval.\n",
    "\n",
    "\"requester_upvotes_plus_downvotes_at_request\": Sum of total upvotes and total downvotes of requester at time of request.\n",
    "\n",
    "\"requester_upvotes_plus_downvotes_at_retrieval\": Sum of total upvotes and total downvotes of requester at time of retrieval.\n",
    "\n",
    "\"requester_user_flair\": Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \"shroom\" (received pizza, but not given, N=1306), or \"PIF\" (pizza given after having received, N=83).\n",
    "\n",
    "\"requester_username\": Reddit username of requester.\n",
    "\n",
    "\"unix_timestamp_of_request\": Unix timestamp of request (supposedly in timezone of user, but in most cases it is equal to the UTC timestamp -- which is incorrect since most RAOP users are from the USA).\n",
    "\n",
    "\"unix_timestamp_of_request_utc\": Unit timestamp of request in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_json(\"train.json\")\n",
    "testdf = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "giver_username_if_known                                  object\n",
       "number_of_downvotes_of_request_at_retrieval               int64\n",
       "number_of_upvotes_of_request_at_retrieval                 int64\n",
       "post_was_edited                                           int64\n",
       "request_id                                               object\n",
       "request_number_of_comments_at_retrieval                   int64\n",
       "request_text                                             object\n",
       "request_text_edit_aware                                  object\n",
       "request_title                                            object\n",
       "requester_account_age_in_days_at_request                float64\n",
       "requester_account_age_in_days_at_retrieval              float64\n",
       "requester_days_since_first_post_on_raop_at_request      float64\n",
       "requester_days_since_first_post_on_raop_at_retrieval    float64\n",
       "requester_number_of_comments_at_request                   int64\n",
       "requester_number_of_comments_at_retrieval                 int64\n",
       "requester_number_of_comments_in_raop_at_request           int64\n",
       "requester_number_of_comments_in_raop_at_retrieval         int64\n",
       "requester_number_of_posts_at_request                      int64\n",
       "requester_number_of_posts_at_retrieval                    int64\n",
       "requester_number_of_posts_on_raop_at_request              int64\n",
       "requester_number_of_posts_on_raop_at_retrieval            int64\n",
       "requester_number_of_subreddits_at_request                 int64\n",
       "requester_received_pizza                                   bool\n",
       "requester_subreddits_at_request                          object\n",
       "requester_upvotes_minus_downvotes_at_request              int64\n",
       "requester_upvotes_minus_downvotes_at_retrieval            int64\n",
       "requester_upvotes_plus_downvotes_at_request               int64\n",
       "requester_upvotes_plus_downvotes_at_retrieval             int64\n",
       "requester_user_flair                                     object\n",
       "requester_username                                       object\n",
       "unix_timestamp_of_request                                 int64\n",
       "unix_timestamp_of_request_utc                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "giver_username_if_known                                object\n",
       "request_id                                             object\n",
       "request_text_edit_aware                                object\n",
       "request_title                                          object\n",
       "requester_account_age_in_days_at_request              float64\n",
       "requester_days_since_first_post_on_raop_at_request    float64\n",
       "requester_number_of_comments_at_request                 int64\n",
       "requester_number_of_comments_in_raop_at_request         int64\n",
       "requester_number_of_posts_at_request                    int64\n",
       "requester_number_of_posts_on_raop_at_request            int64\n",
       "requester_number_of_subreddits_at_request               int64\n",
       "requester_subreddits_at_request                        object\n",
       "requester_upvotes_minus_downvotes_at_request            int64\n",
       "requester_upvotes_plus_downvotes_at_request             int64\n",
       "requester_username                                     object\n",
       "unix_timestamp_of_request                               int64\n",
       "unix_timestamp_of_request_utc                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... the test data has a lot less features than train data does. Let's start by only exploring the data in both, plus whether the requester received pizza. Also, let's split the data into numerical features and text based features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = traindf.as_matrix(columns=['giver_username_if_known',\n",
    "                  'request_id',\n",
    "                  'request_text_edit_aware',\n",
    "                  'request_title',\n",
    "                  'requester_account_age_in_days_at_request',\n",
    "                  'requester_days_since_first_post_on_raop_at_request',\n",
    "                  'requester_number_of_comments_at_request',\n",
    "                  'requester_number_of_comments_in_raop_at_request',\n",
    "                  'requester_number_of_posts_at_request',\n",
    "                  'requester_number_of_posts_on_raop_at_request',\n",
    "                  'requester_number_of_subreddits_at_request',\n",
    "                  'requester_upvotes_minus_downvotes_at_request',\n",
    "                  'requester_upvotes_plus_downvotes_at_request',\n",
    "                  'requester_username',\n",
    "                  'unix_timestamp_of_request_utc'])\n",
    "\n",
    "train_labels = traindf.as_matrix(columns=['requester_received_pizza'])\n",
    "\n",
    "dev_data = train_data[3000:,:]\n",
    "dev_labels = train_labels[3000:,:]\n",
    "\n",
    "train_data = train_data[:3000,:]\n",
    "train_labels = train_labels[:3000,:]\n",
    "\n",
    "test_data = testdf.as_matrix()\n",
    "\n",
    "# just numerical data\n",
    "train_data_numerical = traindf.as_matrix(columns=['requester_account_age_in_days_at_request',\n",
    "                                                  'requester_days_since_first_post_on_raop_at_request',\n",
    "                                                  'requester_number_of_comments_at_request',\n",
    "                                                  'requester_number_of_comments_in_raop_at_request',\n",
    "                                                  'requester_number_of_posts_at_request',\n",
    "                                                  'requester_number_of_posts_on_raop_at_request',\n",
    "                                                  'requester_number_of_subreddits_at_request',\n",
    "                                                  'requester_upvotes_minus_downvotes_at_request',\n",
    "                                                  'requester_upvotes_plus_downvotes_at_request',\n",
    "                                                  'unix_timestamp_of_request_utc'])\n",
    "\n",
    "dev_data_numerical = train_data_numerical[3000:,:]\n",
    "train_data_numerical = train_data_numerical[:3000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction time:\n",
    "\n",
    "Start with using Random Forest on numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.716346153846\n",
      "Accuracy of Random Forest with 10 trees: 0.7375\n",
      "Accuracy of Random Forest with 15 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 25 trees: 0.731730769231\n",
      "Accuracy of Random Forest with 50 trees: 0.734615384615\n",
      "Accuracy of Random Forest with 100 trees: 0.7375\n",
      "Accuracy of Random Forest with 150 trees: 0.733653846154\n",
      "Accuracy of Random Forest with 200 trees: 0.731730769231\n",
      "Accuracy of Random Forest with 250 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 500 trees: 0.735576923077\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(train_data_numerical, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(dev_data_numerical, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73.75% accuracy with 100 trees, not bad. Let's dig into the request title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req_reason = traindf.as_matrix(columns=['request_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req = req_reason.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjectivities = []\n",
    "polarities = []\n",
    "for r in range(len(req)):\n",
    "    tmp = TextBlob(req[r][0])\n",
    "    subjectivities.append(tmp.sentiment.subjectivity)\n",
    "    polarities.append(tmp.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_data_numerical = traindf.as_matrix(columns=['requester_account_age_in_days_at_request',\n",
    "                                                  'requester_days_since_first_post_on_raop_at_request',\n",
    "                                                  'requester_number_of_comments_at_request',\n",
    "                                                  'requester_number_of_comments_in_raop_at_request',\n",
    "                                                  'requester_number_of_posts_at_request',\n",
    "                                                  'requester_number_of_posts_on_raop_at_request',\n",
    "                                                  'requester_number_of_subreddits_at_request',\n",
    "                                                  'requester_upvotes_minus_downvotes_at_request',\n",
    "                                                  'requester_upvotes_plus_downvotes_at_request',\n",
    "                                                  'unix_timestamp_of_request_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = np.array(subjectivities)\n",
    "p = np.array(polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp = np.column_stack((s,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_data_num = np.c_[new_train_data_numerical, sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dev_data = sp[3000:,:]\n",
    "sp_train_data = sp[:3000,:]\n",
    "\n",
    "new_dev_data_numerical = new_train_data_num[3000:,:]\n",
    "new_train_data_num = new_train_data_num[:3000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Random Forest again on:  \n",
    "1) Just the request title sentiments  \n",
    "2) The new numerical array, which joins the previous array with the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 10 trees: 0.727884615385\n",
      "Accuracy of Random Forest with 15 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 25 trees: 0.731730769231\n",
      "Accuracy of Random Forest with 50 trees: 0.729807692308\n",
      "Accuracy of Random Forest with 100 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 150 trees: 0.733653846154\n",
      "Accuracy of Random Forest with 200 trees: 0.735576923077\n",
      "Accuracy of Random Forest with 250 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 500 trees: 0.734615384615\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(sp_train_data, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(sp_dev_data, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on predicting just on sentiment data topped out at 73.557% with 100 trees, which is not an improvement by itself. Let's see if adding the sentiment data to the previous numerical data helped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 10 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 15 trees: 0.727884615385\n",
      "Accuracy of Random Forest with 25 trees: 0.733653846154\n",
      "Accuracy of Random Forest with 50 trees: 0.739423076923\n",
      "Accuracy of Random Forest with 100 trees: 0.736538461538\n",
      "Accuracy of Random Forest with 150 trees: 0.739423076923\n",
      "Accuracy of Random Forest with 200 trees: 0.740384615385\n",
      "Accuracy of Random Forest with 250 trees: 0.740384615385\n",
      "Accuracy of Random Forest with 500 trees: 0.739423076923\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(new_train_data_num, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(new_dev_data_numerical, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... adding sentiment on the request title only boosted accuracy to 74.038%, an increase of only ~1/4 of a percent.  \n",
    "\n",
    "Let's see if adding sentiment for the request text helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req_texts = traindf.as_matrix(columns=['request_text_edit_aware'])\n",
    "req_text = req_texts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjectivities = []\n",
    "polarities = []\n",
    "for r in range(len(req_text)):\n",
    "    tmp = TextBlob(req[r][0])\n",
    "    subjectivities.append(tmp.sentiment.subjectivity)\n",
    "    polarities.append(tmp.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.array(subjectivities)\n",
    "p = np.array(polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp = np.column_stack((s,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dev_data = sp[3000:,:]\n",
    "sp_train_data = sp[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 10 trees: 0.727884615385\n",
      "Accuracy of Random Forest with 15 trees: 0.724038461538\n",
      "Accuracy of Random Forest with 25 trees: 0.731730769231\n",
      "Accuracy of Random Forest with 50 trees: 0.729807692308\n",
      "Accuracy of Random Forest with 100 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 150 trees: 0.733653846154\n",
      "Accuracy of Random Forest with 200 trees: 0.735576923077\n",
      "Accuracy of Random Forest with 250 trees: 0.732692307692\n",
      "Accuracy of Random Forest with 500 trees: 0.734615384615\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(sp_train_data, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(sp_dev_data, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_data_num = np.c_[new_train_data_num, sp_train_data]\n",
    "new_dev_data_numerical = np.c_[new_dev_data_numerical, sp_dev_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.694230769231\n",
      "Accuracy of Random Forest with 10 trees: 0.725961538462\n",
      "Accuracy of Random Forest with 15 trees: 0.714423076923\n",
      "Accuracy of Random Forest with 25 trees: 0.728846153846\n",
      "Accuracy of Random Forest with 50 trees: 0.735576923077\n",
      "Accuracy of Random Forest with 100 trees: 0.734615384615\n",
      "Accuracy of Random Forest with 150 trees: 0.730769230769\n",
      "Accuracy of Random Forest with 200 trees: 0.7375\n",
      "Accuracy of Random Forest with 250 trees: 0.739423076923\n",
      "Accuracy of Random Forest with 500 trees: 0.7375\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(new_train_data_num, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(new_dev_data_numerical, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh. Adding the request text sentiment scores without any preprocessing actually hurt our predicitive accuracy.  \n",
    "\n",
    "Let's explore some of the common vocabularly in request text and how it correlates to success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hungry': 478, 'kids': 54, 'money': 249, 'pizza': 1577, 'please': 136}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = {'pizza':0, 'please':0, 'hungry':0, 'kids':0, 'money':0}\n",
    "for r in range(len(req_text)):\n",
    "    tmp = TextBlob(req[r][0])\n",
    "    for word in common_words.keys():\n",
    "        common_words[word] += tmp.word_counts[word]\n",
    "common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now that we have word counts, do any of these words align with success?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_word(array, word):\n",
    "    word_list = []\n",
    "    for item in range(len(array)):\n",
    "        tmp = TextBlob(array[item][0].lower())\n",
    "        if tmp.word_counts[word] > 0:\n",
    "            word_list.append(1)\n",
    "        else:\n",
    "            word_list.append(0)\n",
    "    return np.array(word_list)\n",
    "\n",
    "has_pizza = has_word(req_text, 'pizza')\n",
    "has_please = has_word(req_text, 'please')\n",
    "has_hungry = has_word(req_text, 'hungry')\n",
    "has_kids = has_word(req_text, 'kids')\n",
    "has_money = has_word(req_text, 'money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has pizza matches train_labels 0.454666666667 % of the time.\n",
      "has please matches train_labels 0.706 % of the time.\n",
      "has hungry matches train_labels 0.696333333333 % of the time.\n",
      "has kids matches train_labels 0.741333333333 % of the time.\n",
      "has money matches train_labels 0.645666666667 % of the time.\n"
     ]
    }
   ],
   "source": [
    "print('has pizza matches train_labels', np.sum(has_pizza[0:3000]==np.ravel(train_labels)) / float(train_labels.shape[0]), '% of the time.')\n",
    "print('has please matches train_labels', np.sum(has_please[0:3000]==np.ravel(train_labels)) / float(train_labels.shape[0]), '% of the time.')\n",
    "print('has hungry matches train_labels', np.sum(has_hungry[0:3000]==np.ravel(train_labels)) / float(train_labels.shape[0]), '% of the time.')\n",
    "print('has kids matches train_labels', np.sum(has_kids[0:3000]==np.ravel(train_labels)) / float(train_labels.shape[0]), '% of the time.')\n",
    "print('has money matches train_labels', np.sum(has_money[0:3000]==np.ravel(train_labels)) / float(train_labels.shape[0]), '% of the time.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We see that pizza, the most commonly used word is not very predictive of success, but the key words may be useful. Let's plug in the non-pizza words into our numerical data matrix and run Random Forest model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words = np.column_stack((has_please, has_hungry, has_kids, has_money))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_dev_data = key_words[3000:,:]\n",
    "keywords_train_data = key_words[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_data_num = np.c_[new_train_data_num, keywords_train_data]\n",
    "new_dev_data_numerical = np.c_[new_dev_data_numerical, keywords_dev_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 10 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 15 trees: 0.753846153846\n",
      "Accuracy of Random Forest with 25 trees: 0.753846153846\n",
      "Accuracy of Random Forest with 50 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 100 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 150 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 200 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 250 trees: 0.754807692308\n",
      "Accuracy of Random Forest with 500 trees: 0.754807692308\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(keywords_train_data, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(keywords_dev_data, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Accuracy boosted to 75.48% using just the key words! Let's try folding those into the existing numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.704807692308\n",
      "Accuracy of Random Forest with 10 trees: 0.726923076923\n",
      "Accuracy of Random Forest with 15 trees: 0.727884615385\n",
      "Accuracy of Random Forest with 25 trees: 0.744230769231\n",
      "Accuracy of Random Forest with 50 trees: 0.75\n",
      "Accuracy of Random Forest with 100 trees: 0.743269230769\n",
      "Accuracy of Random Forest with 150 trees: 0.748076923077\n",
      "Accuracy of Random Forest with 200 trees: 0.738461538462\n",
      "Accuracy of Random Forest with 250 trees: 0.740384615385\n",
      "Accuracy of Random Forest with 500 trees: 0.740384615385\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(new_train_data_num, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(new_dev_data_numerical, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that didn't hepl... maybe we should go back and take out the request_text sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train_data_num2 = np.copy(new_train_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data_num2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since the orignial numerical data had 10 features, the next two we added were request_title\n",
    "# then we added request_text, we want to delete the 13th and 14th columns or the new numerical array\n",
    "new_train_data_num2 = np.delete(new_train_data_num2,[12,13], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 16)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data_num2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dev_data_numerical2 = np.copy(new_dev_data_numerical)\n",
    "new_dev_data_numerical2 = np.delete(new_dev_data_numerical2,[12,13], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 5 trees: 0.694230769231\n",
      "Accuracy of Random Forest with 10 trees: 0.734615384615\n",
      "Accuracy of Random Forest with 15 trees: 0.730769230769\n",
      "Accuracy of Random Forest with 25 trees: 0.738461538462\n",
      "Accuracy of Random Forest with 50 trees: 0.743269230769\n",
      "Accuracy of Random Forest with 100 trees: 0.741346153846\n",
      "Accuracy of Random Forest with 150 trees: 0.736538461538\n",
      "Accuracy of Random Forest with 200 trees: 0.739423076923\n",
      "Accuracy of Random Forest with 250 trees: 0.7375\n",
      "Accuracy of Random Forest with 500 trees: 0.733653846154\n"
     ]
    }
   ],
   "source": [
    "forests = [5, 10, 15, 25, 50, 100, 150, 200, 250, 500]\n",
    "for trees in forests:    \n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=trees)\n",
    "    rf.fit(new_train_data_num2, np.ravel(train_labels))\n",
    "    print('Accuracy of Random Forest with', trees,'trees:',rf.score(new_dev_data_numerical2, np.ravel(dev_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far it doesn't seem like there is much difference between the numerical data available, the sentiment of the request or whether the request contains key words in determining if the request ends in success. Each method so far has ended in only 73-75% accuracy for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
