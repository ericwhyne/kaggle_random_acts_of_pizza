{"nbformat_minor": 0, "cells": [{"execution_count": 1, "cell_type": "code", "source": "# This tells matplotlib not to try opening a new window for each plot.\n%matplotlib inline\n\n# General libraries.\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\n\n# SK-learn libraries for learning.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import BernoulliRBM\nfrom sklearn.svm import SVC\n\n# SK-learn libraries for evaluation.\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\n# SK-learn libraries for feature extraction from text.\nfrom sklearn.feature_extraction.text import *\n\nf = open(\"C:/Users/krunifi/Documents/Work/MIDS/W207/Final/train.json\", \"r\")\ncount = 0\nlabels = []\ntext = []\nnum_data = []\n\ntry:\n    data = json.load(f)\n    \n    for item in data:\n        \n        # extract the outcome labels and text for request and title\n        labels.append(int(item['requester_received_pizza']))\n        #text.append(item['request_text'] + ' ' + item['request_title'])\n        text.append(item['request_text'])\n        \n        # extract numeric data\n        num = []\n        num.append(item['number_of_downvotes_of_request_at_retrieval'])\n        num.append(item['number_of_upvotes_of_request_at_retrieval'])\n        num.append(item['request_number_of_comments_at_retrieval'])\n        num.append(item['requester_account_age_in_days_at_request'])\n        num.append(item['requester_days_since_first_post_on_raop_at_request'])\n        num.append(item['requester_number_of_comments_at_retrieval'])\n        num.append(item['requester_number_of_comments_in_raop_at_retrieval'])\n        num.append(item['requester_number_of_posts_at_request'])\n        num.append(item['requester_number_of_subreddits_at_request'])\n        num.append(len(item['requester_subreddits_at_request']))\n        num.append(item['unix_timestamp_of_request_utc'])\n        num.append(len(item['request_text']))\n        num.append(len(item['request_title']))\n        num_data.append(num)\n\nexcept Exception, e:\n    print \"error reading from file: %s\" %e\n    f.close()\n\nf.close()\nprint len(labels)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "4040\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 2, "cell_type": "code", "source": "train_labels = np.array(labels[:3500])\ntrain_data = np.array(text[:3500])\ntrain_nums = np.array(num_data[:3500])\n\ndev_labels = np.array(labels[3500:])\ndev_data = np.array(text[3500:])\ndev_nums = np.array(num_data[3500:])", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "# normalize the numerical data\nfor i in range(train_nums.shape[1]):\n    max1 = np.mean(train_nums[:,i])\n    max2 = np.mean(dev_nums[:,i])\n    \n    train_nums[:,i] = train_nums[:,i]/max1\n    dev_nums[:,i] = dev_nums[:,i]/max2 \n    \nprint dev_data[150], dev_labels[150]\n\nprint dev_nums.shape, train_nums.shape\nprint np.max(dev_nums[:,1])", "outputs": [{"output_type": "stream", "name": "stdout", "text": "http://m.youtube.com/?reason=8&amp;rdm=3676#/watch?v=V09Mt66O9_c&amp;desktop_uri=%2Fwatch%3Fv%3DV09Mt66O9_c 0\n(540L, 13L) (3500L, 13L)\n14.0579238529\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "def better_preprocessor(s):\n\n    # remove links and replace with string \"hyperlink\"\n    links = re.compile(u'\\\\bhttp\\w+\\\\b')\n    # remove non-alphanumerics\n    non_alpha = re.compile(u'[\\W_]+', re.UNICODE)\n    # change all number sequences to single '0'\n    num = re.compile(u'[0-9]+', re.UNICODE)\n    # list of common English suffixes to remove\n    suff = re.compile(u'(al|ance|ence|dom|ed|er|or|ism|ist|ity|ty|ment|ship|sion|ing|s|ly|ation|tion|able|ible|ate|en|ify|fy|ize|ise|ful|ic|ical|ious|ous|ish|ive)\\\\b', re.UNICODE)\n    # list of common English prefixes to remove\n    pre = re.compile(u'\\\\b(an|ante|anti|auto|circum|co|com|con|contra|de|dis|en|ex|extra|hyper|in|im|il|ir|inter|intra|macro|micro|mid|mis|mono|non|over|post|pre|pro|re|semi|sub|super|trans|tri|un)', re.UNICODE)\n    # remove words with one or two characters only (treat as stopwords)\n    stop = re.compile(u'\\\\b([\\w]{1,2})\\\\b', re.UNICODE)\n\n    # apply filters\n    t = links.sub(u'hyperlink', s)\n    t = non_alpha.sub(u' ', t)\n    t = num.sub(u\" 0 \", t)\n    t = suff.sub(u' ', t)\n    t = pre.sub(u' ', t)\n    t = stop.sub(u' ', t)\n    return t", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "# use vectorize text data and then train logistic regression\ndef trainLM():\n    vectorizer = CountVectorizer(analyzer=\"word\", ngram_range=[1,2])\n    X = vectorizer.fit_transform(train_data)\n    Y = vectorizer.transform(dev_data)\n    vocab = vectorizer.get_feature_names()\n    \n    print X.shape, Y.shape\n    \n    lm = LogisticRegression()\n    lm.fit(X, train_labels)\n    pred_labels = lm.predict(Y)\n    \n    score = metrics.f1_score(dev_labels, pred_labels)\n    print \"base f1 =\", score\n    \n    for row in range(lm.coef_.shape[0]):\n        maxind = np.fabs(lm.coef_[row]).argsort()[-5:]\n        for item in maxind:\n            print vocab[item]\n    \n    # vectorize data using the better preprocessor\n    better_vect = CountVectorizer(preprocessor=better_preprocessor)\n    better_X = better_vect.fit_transform(train_data)\n    better_Y = better_vect.transform(dev_data)\n    vocab2 = better_vect.get_feature_names()\n    \n    # run logistic regression on this data and report f1 score\n    better_lm = LogisticRegression()\n    better_lm.fit(better_X, train_labels)\n    better_labels = better_lm.predict(better_Y)\n    print \"Improved f1 =\", metrics.f1_score(dev_labels, better_labels)\n    \n    for row in range(better_lm.coef_.shape[0]):\n        #maxind2 = np.fabs(better_lm.coef_[row]).argsort()[-5:]\n        maxind2 = better_lm.coef_[row].argsort()[-5:]\n        for item in maxind2:\n            print vocab2[item]\n    \ntrainLM()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "(3500, 107742) (540, 107742)\nbase f1 = 0.290155440415\nfriend\nlove pie\ncould make\nwhen have\nfood for\nImproved f1 = 0.27358490566\ndraft\naid\nsurpr\nbattle\nNEED\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "# train a simple KNN model and check accuracy\n# this uses the numerical data from json input\ndef trainKNN():\n    # value for k from gridsearch output\n    model = KNeighborsClassifier(n_neighbors=47)\n    model.fit(train_nums, train_labels)\n    pred_labels = model.predict(dev_nums)\n    \n    correct = (pred_labels == dev_labels)\n    accuracy = 1.0 * np.sum(correct) / len(pred_labels)\n    print \"%.03f\" %accuracy\n\n# run gridsearch to find best k value\ndef findK():\n    # range is from an iterative process to narrow down\n    params = {'n_neighbors': range(38,56,1)}\n    search = GridSearchCV(KNeighborsClassifier(), params)\n    search.fit(train_nums, train_labels)\n    \n    print \"the best parameter is k=%f\\n\" %search.best_params_['n_neighbors']\n    print \"summary of all params:\\n\", search.grid_scores_", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 7, "cell_type": "code", "source": "# train a simple BernoulliNB model and check accuracy\n# this uses the numeric data captured from json input\ndef trainBern():\n    bern = BernoulliNB(alpha=0)\n    bern.fit(train_nums, train_labels)\n    pred_labels = bern.predict(dev_nums)\n    \n    # display the accuracy\n    correct = (pred_labels == dev_labels)\n    accuracy = 1.0 * np.sum(correct) / len(dev_labels)\n    print \"accuracy for BernoulliNB is %.03f\" %accuracy\n\n# run gridsearch to find parameters for NB model\ndef bernParams():\n    params = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n    search = GridSearchCV(BernoulliNB(), params)\n    search.fit(train_nums, train_labels)\n    \n    print \"the best parameter is k=%f\\n\" %search.best_params_['alpha']\n    print \"summary of all params:\\n\", search.grid_scores_", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 8, "cell_type": "code", "source": "trainKNN()\n#findK()\ntrainBern()\n#bernParams()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.767\naccuracy for BernoulliNB is 0.757\n"}, {"output_type": "stream", "name": "stderr", "text": "C:\\Users\\krunifi\\Documents\\Work\\WinPython\\WinPython-64bit-2.7.9.4\\python-2.7.9.amd64\\lib\\site-packages\\sklearn\\naive_bayes.py:726: RuntimeWarning: divide by zero encountered in log\n  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\nC:\\Users\\krunifi\\Documents\\Work\\WinPython\\WinPython-64bit-2.7.9.4\\python-2.7.9.amd64\\lib\\site-packages\\sklearn\\naive_bayes.py:729: RuntimeWarning: invalid value encountered in add\n  jll += self.class_log_prior_ + neg_prob.sum(axis=1)\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "# random forest classifier \ndef trainRF():\n    model = RandomForestClassifier()\n    model.fit(train_nums, train_labels)\n    pred_labels = model.predict(dev_nums)\n    \n    # display the accuracy\n    correct = (pred_labels == dev_labels)\n    accuracy = 1.0 * np.sum(correct) / len(dev_labels)\n    print \"accuracy for RandomForest is %.03f\" %accuracy\n    \ntrainRF()", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}